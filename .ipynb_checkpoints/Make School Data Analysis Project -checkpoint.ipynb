{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive C is Windows\n",
      " Volume Serial Number is 361D-A6A7\n",
      "\n",
      " Directory of C:\\Users\\Don\\Desktop\\github\\DS-1-Data-Analysis\n",
      "\n",
      "02/06/2018  02:26 PM    <DIR>          .\n",
      "02/06/2018  02:26 PM    <DIR>          ..\n",
      "02/05/2018  12:12 PM             8,196 .DS_Store\n",
      "02/05/2018  12:12 PM    <DIR>          .ipynb_checkpoints\n",
      "02/05/2018  12:12 PM             1,876 00__Test_Installation.ipynb\n",
      "02/06/2018  12:38 PM            71,797 01__Descriptive_Statistics.ipynb\n",
      "02/05/2018  12:12 PM           196,865 02__Data_Visualization.ipynb\n",
      "02/05/2018  12:12 PM             3,941 03.5__Converting_Z-scores_to_Probability.ipynb\n",
      "02/05/2018  12:12 PM            12,671 03__Normal_Distribution_and_CLT.ipynb\n",
      "02/05/2018  12:12 PM            14,651 CLT practice.ipynb\n",
      "02/05/2018  12:12 PM    <DIR>          datasets\n",
      "02/05/2018  12:12 PM    <DIR>          img\n",
      "02/05/2018  12:12 PM             8,942 Installation_Instructions.md\n",
      "02/06/2018  02:26 PM             5,984 Make School Data Analysis Project .ipynb\n",
      "02/05/2018  12:12 PM               355 README.md\n",
      "02/05/2018  12:12 PM            16,386 Visualization Practice and Examples.ipynb\n",
      "              11 File(s)        341,664 bytes\n",
      "               5 Dir(s)  78,931,963,904 bytes free\n",
      "C:\\Users\\Don\\Desktop\\github\\DS-1-Data-Analysis\\datasets\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import glob\n",
    "import os\n",
    "import sys\n",
    "from collections import OrderedDict\n",
    "%matplotlib inline\n",
    "np.random.seed(1547)\n",
    "\n",
    "\n",
    "#import blob to make reading of files in easier\n",
    "%ls\n",
    "%cd datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for name in glob.glob('/datasets/SA Feedback Surveys_FINAL/2017/2017/Student Feedback Surveys-Superview.csv'):\n",
    "    print (name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for name in glob.glob('2016/*'):\n",
    "    print (name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(glob.glob('2017/Student Feedback Surveys-Superview.csv'))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MS2017_data_df= pd.read_csv('2017/Student Feedback Surveys-Superview.csv')\n",
    "MS2017_data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#investigationg head and tail for EOF Errora\n",
    "MS2017_data_df.head()\n",
    "MS2017_data_df.tail()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Beginning of globbing files for the 2016 folders... T_T;;\n",
    "#MS2016_data_df= pd.read_csv('2016/Anon Week 7 Feedback - Taipei.csv')\n",
    "#MS2016_data_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# will take all of the 2016 files ( yes i know theyre un sorted) and put them into one giant file, as a test for later interations\n",
    "files = sorted(glob.iglob('2016/*.csv'))\n",
    "header = OrderedDict()\n",
    "data = []\n",
    "for filename in files:\n",
    "    with open(filename, 'r') as fin:\n",
    "        csvin = csv.DictReader(fin)\n",
    "        header.update(OrderedDict.fromkeys(csvin.fieldnames))\n",
    "        data.append(next(csvin))\n",
    "with open('output_filename_version2.csv', 'w', newline='') as fout:\n",
    "    csvout = csv.DictWriter(fout, fieldnames=list(header))\n",
    "    csvout.writeheader()\n",
    "    csvout.writerows(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# failed attempt but keeping code to frankenstien it in a later interations\n",
    "MS2016_data_df= pd.read_csv('output_filename_version2.csv')\n",
    "MS2016_data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#ideas for mergin conflicting data in these data sets\n",
    "# 1. find words in the keys( data frams are saved as dict) like \"satisfation\",\"pace\", \"tract\", \"location\" since these should be shared amoungst alot of them\n",
    "# 2. open each one and do the above as a function\n",
    "#3. ask alan for help monday"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
